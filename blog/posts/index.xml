<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on The Evening Paper</title>
    <link>https://millyz.github.io/blog/posts/</link>
    <description>Recent content in Posts on The Evening Paper</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Wed, 13 Feb 2019 10:50:14 +0800</lastBuildDate>
    <atom:link href="https://millyz.github.io/blog/posts/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>A ZigZag-Decodable Code with the MDS Property for Distributed Storage Systems, ISIT13</title>
      <link>https://millyz.github.io/blog/posts/zzdc-isit13/</link>
      <pubDate>Wed, 13 Feb 2019 10:50:14 +0800</pubDate>
      
      <guid>https://millyz.github.io/blog/posts/zzdc-isit13/</guid>
      <description>Summary This paper presents ZigZag-Decodable Code (ZD), a new vector code that has the MDS property. For data retrieval, only XOR operations are needed while for node failure, uncoded and exact repair can be performed. Note that uncoded repair means that a newcomer (to replace the failed node) can simply download data from d survivor nodes without any encoding/decoding operations. It allows fast encoding and decoding (operate over GF(2)) because it does not require a large finite-field size.</description>
      <content type="html"><![CDATA[<h3 id="summary">Summary</h3>

<p>This paper presents ZigZag-Decodable Code (ZD), a new vector code that has the MDS property. For data retrieval, <strong>only XOR operations are needed while for node failure, uncoded and exact repair can be performed</strong>. Note that <strong>uncoded repair</strong> means that a newcomer (to replace the failed node) can simply download data from <em>d</em> survivor nodes without any encoding/decoding operations. It allows <strong>fast encoding and decoding</strong> (operate over GF(2)) because it does not require a large finite-field size. (I will test it later, comparing it with ISA-L). But it requires a little more storage space as the length of <strong>coded block</strong> is larger than the original length of data blocks.</p>

<p>Two main properties of ZigZag-Decodable code is: 1) there is no limitation on the number of data blocks; 2) the data blocks are guaranteed to be recovered. ZigZag decoding was originally designed to recover collied packets in wireless networks because collisions can be represented algebraically as a linear combination of original packets.</p>

<p>Then I will explain how to construct a code and conduct recovery given <em>N</em> and <em>K</em> via an example.</p>

<h4 id="code-construction">Code construction</h4>

<ul>
<li>Construction

<ul>
<li>$K​$ data blocks, $L​$ bits of each block, $s_{i, j}​$ is the ($j+1​$)-th bit of block $i​$. Here both $i​$ and $j​$ start from 0. Block $i​$ is present by the polynomial: $s_i(z) = s_{i, 0} + s_{i, 1}z + s_{i, 2}z^2 + ... + s_{i, L-1}z^{L-1}​$.</li>
<li>Then encode $K​$  data blocks to $N​$ blocks, each of which has $L+r​$ bits. The $i+1​$-th coded block is present as: $c_i(z) = {\alpha_{i, 0}}{s_0(z)} + {\alpha_{i, 1}}{s_1(z)} + ... + {\alpha_{i, K-1}}{s_{K-1}(z)}​$. That is, $\mathbf{c}(z) = \mathbf{A}(z)\mathbf{s}(z)​$.</li>
<li>Now the question is what does $\mathbf{A}(z)​$ look like. $\mathbf{A}(z)​$ is partitioned into two blocks: $\mathbf{A}(z) \triangleq \begin{bmatrix} \mathbf{I}_{K} \ \mathbf{B}(z) \end{bmatrix}​$. Here $\mathbf{I}_{K}​$ is $K \times K​$ identity matrix and $\mathbf{B}(z)​$ is a $(N-K) \times K​$ matrix, where $\beta_{i,j}(z) \triangleq  z^{(i+1)j}​$. Thus $r = (N-K)(K-1)​$.</li>
</ul></li>
<li>Example

<ul>
<li>When $K = 3$ and $N=6$, $\mathbf{A}(z) \triangleq \begin{bmatrix} 1 &amp; 0 &amp; 0 \ 0 &amp; 1 &amp; 0 \ 0 &amp; 0 &amp; 1\ 1 &amp; z &amp; z^2 \ 1 &amp; z^2 &amp; z^4 \ 1 &amp; z^3 &amp; z^6\  \end{bmatrix}$. Then $r = 6$.</li>
<li><figure><img src="/blog/images/zzdc-isit13-1.png" alt="All coded blocks."></figure></li>
</ul></li>
</ul>

<h4 id="decoding">Decoding</h4>

<ul>
<li>Here I still use the above example to illustrate the decoding process. As ZD has MDS property, meaning that any 3 blocks can recover the original data. Thus we can have the following cases:

<ul>
<li>2 data blocks, 1 parity block. This is simple because we can extract another data blocks by XORing these three blocks.</li>
<li>1 data block, 2 parity blocks. We first XORing the data block with parity blocks respectively. Then we can use zigzag to get the 2 data blocks from updated parity blocks.</li>
<li>3 parity blocks ($c_4$, $c_5$, $c_6$). I think this case is the most complicated. My thinking is the following:</li>
<li>Get $s_{1,0}$, $s_{1,1}$, $s_{1,2}$ from $c_6$;</li>
<li>Get $s_{2, 0}$, $s_{1, 3}$, $s_{2, 1}$, $s_{1, 4}$ from $c_5$ and $c_6$;</li>
<li>Then use all three blocks to solve all bits:

<ul>
<li>$c_4$ --&gt; $s_{30}$, $c_5$ --&gt; $s_{22}$, $c_6$ --&gt; $s_{15}$</li>
<li>$c_4$ --&gt; $s_{31}$, $c_5$ --&gt; $s_{23}$, $c_6$ --&gt; $s_{16}$</li>
<li>$c_4$ --&gt; $s_{32}$, $c_5$ --&gt; $s_{24}$, $c_6$ --&gt; $s_{17}$</li>
<li>...</li>
</ul></li>
</ul></li>
</ul>

<h3 id="strengths">Strengths</h3>

<h3 id="weaknesses">Weaknesses</h3>

<ul>
<li>In the equation, $i$ and $j$ sometimes start from 0, sometimes start from 1. This inconsistency makes reader a litter hard to follow the math.</li>
</ul>

<h3 id="references">References</h3>

<ul>
<li><a href="https://scholars.cityu.edu.hk/en/theses/theses(970c09bc-c62d-4cf2-8ccf-ad4d5fccafa9).html">Zigzag-decodable Codes: Constructions and Applications</a>, Thesis of Xueqing GONG</li>
</ul>
]]></content>
    </item>
    
    <item>
      <title>SageDB:A Learned Database System, CIDR19</title>
      <link>https://millyz.github.io/blog/posts/sagedb-cidr19/</link>
      <pubDate>Tue, 12 Feb 2019 10:40:49 +0800</pubDate>
      
      <guid>https://millyz.github.io/blog/posts/sagedb-cidr19/</guid>
      <description>The paper targets on the problem caused by the general design of modern data processing systems, which do not consider the characteristics of the particular application and data of the user. The main idea of SageDB is to design a highly specialized DB for an application through code synthesis and machine learning. Though previous work has explored the use of machine learning in DB design, the authors argue that the learned components can fully replace core components of a database system such as index structures, sorting algorithm, or even query executor.</description>
      <content type="html"><![CDATA[

<p>The paper targets on the problem caused by the general design of modern data processing systems, which do not consider the characteristics of the particular application and data of the user. The main idea of SageDB  is to design a highly specialized DB for an application through code synthesis and machine learning. Though previous work has explored the use of machine learning in DB design, the authors argue that the learned components can <strong>fully replace core components</strong> of a database system such as <em>index structures, sorting algorithm, or even query executor</em>. The advantages of SageDB can be summarized as follows: 1) The DBMS can profit from the specialized hardware with learned components; 2) It has more flexibility to explore the trade-off between performance and accuracy; 3) It is easy to automatically create efficient data structures. SageDB has been developed as part of MIT&rsquo;s new Data Systems for AI Lab (DSAIL), whose focus is to build a new analytical (OLAP) environment.</p>

<h3 id="summary">Summary</h3>

<p>The key idea of SageDB is &ldquo;to build or select (synthesize) the best implementation of each component of the data processing engine for a particular application&rdquo;. The authors argue that the different types of customization (customization through configuration, algorithm picking, self-design, and learning) can be composed via SageDB.</p>

<p>A key challenge mentioned in the paper is &ldquo;choosing the right model for SageDB&rsquo;s brain&rdquo;. Their solution is to build or select (synthesize) the best implementation of each component of the data processing engine for a particular application. This synthesis is done by first learning one or more data distributions, workload, and hardware models, which forms the &ldquo;brain&rdquo; of SageDB. As the authors said, individual components can often share the previously learned models. Then, SageDB tries its best to compose a database from the following perspectives:</p>

<ul>
<li><strong>Data access</strong></li>
<li><strong>Query execution</strong></li>
<li><strong>Query optimization</strong></li>
<li><strong>Advanced analytics</strong></li>
</ul>

<h3 id="strengths">Strengths</h3>

<ul>
<li>The ides seems interesting to me, which is a comprehensive and automatic approach to design and implement  a database.</li>
</ul>

<h3 id="weaknesses">Weaknesses</h3>

<ul>
<li>SageDB combines each best-chosen together to form an entire database, which does not illustrate the appropriate method and estimation to form a best entity by balancing different properties. I&rsquo;m not familiar with the application of machine learning in DBMS but it seems that there are a large amount of works to employ machine leaning in DBMS for a specific purpose. One previous work is RMI structure presented in SIGMOD &lsquo;18, &ldquo;The case for learned index structure&rdquo;.</li>
</ul>

<h3 id="notations">Notations</h3>

<ul>
<li>OLAP vs. OLTP

<ul>
<li>OLAP, online analytical processing, deals with historical data or archival data.</li>
<li>OLTP, online transactional processing, deals with a large number of short on-line transactions.</li>
<li><a href="https://stackoverflow.com/questions/21900185/what-are-oltp-and-olap-what-is-the-difference-between-them" target="_blank">Difference summarized on stackoverflow</a>:</li>
<li>OLTP (On-line Transaction Processing) is involved in the operation of a particular system. OLTP is characterized by a large number of short on-line transactions (INSERT, UPDATE, DELETE). The main emphasis for OLTP systems is put on very fast query processing, maintaining data integrity in multi-access environments and an effectiveness measured by number of transactions per second. In OLTP database there is detailed and current data, and schema used to store transactional databases is the entity model (usually 3NF). It involves Queries accessing individual record like Update your Email in Company database.</li>
<li>OLAP (On-line Analytical Processing) deals with Historical Data or Archival Data. OLAP is characterized by relatively low volume of transactions. Queries are often very complex and involve aggregations. For OLAP systems a response time is an effectiveness measure. OLAP applications are widely used by Data Mining techniques. In OLAP database there is aggregated, historical data, stored in multi-dimensional schemas (usually star schema). Sometime query need to access large amount of data in Management records like what was the profit of your company in last year.</li>
</ul></li>
</ul>
]]></content>
    </item>
    
    <item>
      <title>Cassandra - A Decentralized Structured Storage System</title>
      <link>https://millyz.github.io/blog/posts/cassandra/</link>
      <pubDate>Mon, 28 Jan 2019 17:21:43 +0800</pubDate>
      
      <guid>https://millyz.github.io/blog/posts/cassandra/</guid>
      <description>Cassandra is a distributed storage system for structured data spread out across many commodity servers, while providing high availability, durability, and scalability. It achieves high write throughput and read efficiency.
System architecture  Partition, Membership, and Scalability  Cassandra partitions data across the cluster using consistent hashing (an order preserving hash function). Each data item identified by a key is assigned to a node, which is the coordinator of for this key.</description>
      <content type="html"><![CDATA[

<p>Cassandra is a distributed storage system for structured data spread out across many commodity servers, while providing high availability, durability, and scalability. It achieves high write throughput and read efficiency.</p>

<h3 id="system-architecture">System architecture</h3>

<ul>
<li>Partition, Membership, and Scalability

<ul>
<li>Cassandra partitions data across the cluster using <a href="https://www.akamai.com/es/es/multimedia/documents/technical-publication/consistent-hashing-and-random-trees-distributed-caching-protocols-for-relieving-hot-spots-on-the-world-wide-web-technical-publication.pdf" target="_blank">consistent hashing</a> (an order preserving hash function). Each data item identified by a key is assigned to a node, which is the <strong>coordinator</strong> of for this key. The advantage of consistent hashing is that departure or arrival of a node only affects its neighbours but this may result in load imbalance and ignorance of heterogeneity. To tackle this, Cassandra analyzes local information on the ring and have lightly loaded nodes move on the ring to alleviate heavily-loaded servers.</li>
<li>Cluster membership in Cassandra is based on Scuttlebutt, an efficient anti-entropy Gossip based mechanism.</li>
<li>When a node joins the cluster, Cassandra would move some data on ole machines to the new one. <strong>Q</strong>, then how consistent hashing works when this happens and later read/write workloads?</li>
</ul></li>
<li>Failure handling

<ul>
<li>Replication

<ul>
<li>Each data item is replicated at N hosts and its coordinator takes in charge of the replicas.</li>
<li>Cassandra provides various replication policies, &ldquo;rack unaware&rdquo;, &ldquo;rack aware&rdquo;, and &ldquo;datacenter aware&rdquo;. One point is to satisfy the requirement of placement. Here Cassandra elects a leader amongst the nodes using Zookeeper, which tells a newly-joined node what ranges they are responsible for.</li>
<li>Cassandra considers data center failure where each row is replicated across multiple data centers.</li>
</ul></li>
<li>Failure detection

<ul>
<li>Cassandra implements <strong>accrual failure detector</strong>, where the failure detection module emits a value representing a suspicion level for each of monitored nodes.</li>
</ul></li>
<li>Data persistence

<ul>
<li>Typical write operation writes data into a commit log for durability.</li>
<li>All writes are sequential to disk and generate an index for efficient lookup based on row key.</li>
<li>To look up a key efficiently on disk, Cassandra employs a bloom filter to summarize the keys in each file.</li>
</ul></li>
</ul></li>
</ul>

<h2 id="references">References</h2>

<ul>
<li><a href="https://www.cs.cornell.edu/projects/ladis2009/papers/lakshman-ladis2009.pdf" target="_blank">Paper</a></li>
<li><a href="http://cassandra.apache.org/" target="_blank">Apache Cassandra</a></li>
</ul>
]]></content>
    </item>
    
    <item>
      <title>An Analysis of Network-Partitioning Failures in Cloud Systems</title>
      <link>https://millyz.github.io/blog/posts/neat-osdi18/</link>
      <pubDate>Fri, 07 Dec 2018 13:19:26 +0800</pubDate>
      
      <guid>https://millyz.github.io/blog/posts/neat-osdi18/</guid>
      <description>This paper studies 136 system failures attributed to network-partitioning faults from 25 widely used distributed systems. They find that the majority of the failures leads to catastrophic effects and can be easily detected by isolating a single node. The challenging is that the number of test cases that one must consider is extremely large. Then they identify ordering, timing and network fault characteristics to simplify testing. They built NEAT, a testing framework that simplifies the coordination of multiple clients and can inject different types of network-partitioning faults.</description>
      <content type="html"><![CDATA[

<p>This paper studies 136 system failures attributed to network-partitioning
faults from 25 widely used distributed systems. They find that the majority of
the failures leads to catastrophic effects and can be easily detected by
isolating a single node. The challenging is that the number of test cases that
one must consider is extremely large. Then they identify ordering, timing and
network fault characteristics to simplify testing. They built <strong>NEAT</strong>, a
testing framework that simplifies the coordination of multiple clients and can
inject different types of network-partitioning faults.</p>

<p>Why they focus on network partitioning attributes to two reasons:</p>

<ol>
<li>Tolerating these faults is complex. &ldquo;Network-partitioning fault tolerance
pervades the design of all system layers, from the communication middleware
and data replication to user API definition and semantics, and it dictates
the availability and consistency levels a system can achieve.&rdquo;</li>
<li>Network-partitioning faults occur frequently in production networks.</li>
</ol>

<p>They classify the network-partitioning faults to the following:</p>

<ul>
<li><em>Complete network partitioning</em>, divides the network into two disconnected
parts. This kind of faults happen at different scales, such as geo-replicated
systems, enterprise network. These faults can be caused by ToR failures, NIC
failures, and correlated failures of multiple devices.</li>
<li><em>Partial network partitioning</em>, leads to the division of nodes into three
groups where two groups are disconnected while the third group can
communicate with the two groups.</li>
<li><em>Simplex network partitioning</em>, permits traffic to flow in on direction, but
not in the other.</li>
</ul>

<h3 id="findings">Findings:</h3>

<ol>
<li>80% of the studied failures leads to a catastrophic impact with data loss
being the most common (27%).  Stales reads is the second most common (13%)
where is is catastrophic only when the system promises strong consistency.</li>
<li>90% of the failures are silent, whereas the rest produce warnings that are
unatonable (i.e., all returned warnings to client are confusing, with no
clear mechanism for resolution.)</li>
<li>21% of the failures lead to permanent damage to the system, meaning that the
damage persists even after the network partition heals.</li>
<li>Leader election (40%), configuration change (20%), request routing (13%),
and data consolidation (14%) are the most vulnerable mechanisms to network
partitioning.</li>
<li>64% of the failures either do not require any client access or require
client access to only one side of the network partition.</li>
<li>69% of the failures require a complete partition, a significant percentage
of them 29%) are caused by partial partitions.</li>
<li>A majority (83%) of the failures triggered by a network partition require an
additional three or fewer input events to manifest.</li>
<li>To expose the failures, they do no tonly need to explore the combination of
these events, but also the different permutation of events, making the event
space extremely large.</li>
<li>88% of the failures manifest by isolating a single node, with 45% of the
failures manifest by isolating any replica.</li>
<li>80% of the failures are either deterministic or have known timing
constraints.</li>
<li>The resolution of 47% of the failures required redesigning a system
mechanism.</li>
<li>All failures can be reproduced on a cluster of five nodes while 83% of the
failures are reproducible with three nodes only.</li>
<li>93% of the failures can be reproduced through tests by using a fault
injection framework such as NEAT.</li>
</ol>

<h3 id="neat-framework">NEAT Framework</h3>

<h3 id="insights">Insights</h3>

<h2 id="references">References:</h2>

<ul>
<li><a href="https://dsl.uwaterloo.ca/projects/neat/" target="_blank">NEAT Project</a></li>
</ul>
]]></content>
    </item>
    
    <item>
      <title>Spiffy: Enabling File-System Aware Storage Applications, FAST &#39;18</title>
      <link>https://millyz.github.io/blog/posts/spiffy-fast18/</link>
      <pubDate>Wed, 05 Dec 2018 09:27:56 +0800</pubDate>
      
      <guid>https://millyz.github.io/blog/posts/spiffy-fast18/</guid>
      <description>This paper presents Spiffy, an annotation language for specifying the on-disk format of a file system. Spiffy allows file-system developers to unambiguously specify the physical layout of the file system where the annotations handle low-level details. Then, the annotation is compiled to generate a Spiffy library that provides interfaces for type-safe parsing, traversal and update of file system metadata. This generic library simplify the development of applications that work across different file system, which reduces the burden of developing file-system aware storage applications.</description>
      <content type="html"><![CDATA[<p>This paper presents <em>Spiffy</em>, an annotation language for specifying the on-disk
format of a file system. Spiffy allows file-system developers to unambiguously
specify the physical layout of the file system where the annotations handle
low-level details. Then, the annotation is compiled to generate a Spiffy
library that provides interfaces for type-safe parsing, traversal and update of
file system metadata. This generic library simplify the development of
applications that work across different file system, which reduces the burden
of developing file-system aware storage applications.</p>

<p>The motivation of this work can be summarized as below:</p>

<ul>
<li>Many file-system aware storage applications requires a detailed understanding
of the format of a file system. There applications operate in an offline or
online context: offline tools include a file system checker, a data recovery
tool while online storage applications include I/O shepherding, Recon.</li>
<li>Developers of the file-system aware storage applications have to perform
ad-hoc processing of files system metatdata because most file systems do not
provide the requisite library code. Even when such library code exists, its
interface may not be usable by all storage applications. To make matters
worse, many file systems do not provide detailed and up-to-date documentation
of their metatdata format.</li>
</ul>

<p>The complexity of modern file systems raises several challenges for
specification-based approach because many aspects of file system structures and
their relationships are not captured by their declarations in header files.
They list the following points:</p>

<ul>
<li>An on-disk pointer in a file-system structure may be implicitly specified;</li>
<li>The interpretation of file-system structures may depend on other structures;</li>
<li>The semantics of metadata fields may be context-sensitive;</li>
<li>The placement of structures on disk may be implicit in the code that operates
on them and some structures may not be declared at all;</li>
<li>It is impractical to load all file-system metadata into memory for large file
systems.</li>
</ul>

<p>Therefore, the authors design the annotations considering the following
challenges:</p>

<ul>
<li><strong>File system pointers</strong>, associating and <em>address space</em> with each file
system pointer where each address space specifies a mapping of its address to
physical locations.</li>
<li><strong>Cross-structure dependencies</strong>, use a path-based name resolution mechanism
as every file system structure is accessed along a path of pointers starting
from the super block.</li>
<li><strong>Context-sensitive types</strong>, use a <em>when</em> expression to support
context-sensitive types at runtime.</li>
<li><strong>Computed fileds</strong>, annotate such information as an implicit field of the
super block that is computed at runtime.</li>
<li><strong>Metadata granularity</strong>, define an <em>access unit</em> for file ystem structures
to realize on-demand loading.</li>
<li><strong>Constraint checking</strong>, add constraint annotations to specify the
constraints for each structure.</li>
</ul>

<p>Then they present Spiffy API and annotate three different types of file
systems: Ext4 (update-in-place), Btrfs (copy-on-write) and F2FS
(log-structured). Moreover, they implement five file-system aware storage
applications to validate the effectiveness of Spiffy.</p>

<p>I think Spiffy seems quite useful and powerful and this paper really did a
  comprehensive work.</p>
]]></content>
    </item>
    
    <item>
      <title>Overload Control for Scaling WeChat Microservices, SoCC &#39;18</title>
      <link>https://millyz.github.io/blog/posts/dagor-socc18/</link>
      <pubDate>Mon, 03 Dec 2018 17:21:30 +0800</pubDate>
      
      <guid>https://millyz.github.io/blog/posts/dagor-socc18/</guid>
      <description>This paper presents the microservice architecture and overload control at WeChat. We can take a look how such a massive application runs internally, which is the point attracting me most. This paper is easy to follow and understand. In conclusion, the technique introduced in this paper seems straightforward and practical.
The motivation of this paper is quite strong and very clear. &amp;ldquo;Workload handled by the WeChat backend is always varying over time, and the fluctuation pattern differs among diverse situations&amp;rdquo;.</description>
      <content type="html"><![CDATA[<p>This paper presents the microservice architecture and overload control at
WeChat. We can take a look how such a massive application runs internally,
which is the point attracting me most. This paper is easy to follow and
understand. In conclusion, the technique introduced in this paper seems
straightforward and practical.</p>

<p>The motivation of this paper is quite strong and very clear. &ldquo;Workload handled
by the WeChat backend is always varying over time, and the fluctuation pattern
differs among diverse situations&rdquo;. The request amount during peak hours is
about 3 times larger than the daily average, even 10 times during the period of
Chinese Lunar New Year. Obviously, it is not economic to run physical machines
based on the maximum request amount. Therefore, overload control mechanism is
required to adaptively tolerate the workload fluctuation at system runtime.</p>

<p>This paper targets to solve <em>subsequent overload</em>, where more than one
overloaded services or the single overloaded service is invoked multiple times
by the associated upstream services. In this scenario, the inappropriate load
shedding can aggravate the overload situation. Basically, the upstream service
re-sends requests to a overloaded server and a larger fraction of requests
fails, which degrade the overall throughput. Therefore, simple load shedding
does not work here.  The authors need to tackle with the following challenges
when designing overload control algorithm for WeChat:</p>

<ul>
<li>No single entry point for service requests sent to the Wechat backend.

<ul>
<li>Centralized load monitoring at a global entry point is not valid.</li>
<li>Fail to pinpoint the slow service due to the complex call path.</li>
</ul></li>
<li>Excessive request abortion not only wastes the computational resources but
also increases the latency of service response.

<ul>
<li>Call for proper management on load shedding.</li>
</ul></li>
</ul>

<p>The proposed overload control scheme for WeChat is called DAGOR, consisting
<strong>overload detection</strong> and <strong>service admission control</strong>.</p>

<p>DAGOR takes the <em>queuing time</em> to profile the load status of a server. The
queuing time is measured by the time difference between the request arrival and
its processing being started at the server. When a server becomes overloaded
due to resource exhaustion, the queuing time rises proportional to the excess
workload. They do not use the response time because it additionally counts the
request processing time, which may be inaccurate to reflect the load status.</p>

<p>For service admission control, DAGOR mainly considers <em>business-oriented
admission control</em>, <em>user-oriented admission control</em>, <em>adaptive admission
control</em> and <em>collaborative admission control</em>:</p>

<ul>
<li>Business-oriented admission control, the request with higher business
significance and greater impact on user experience is of the higher priority.
For example, payment service has higher priority than messaging while
messaging is more important than moments. The business priorities are
predefined and stored in a hash table, which remains stable.</li>
<li>User-oriented admission control, discard the requests of some user which has
lower user priority at the same business priority. The user priority is
generated by a hash function using the user ID and changes every hour for
fairness. They also mention session-oriented admission control, which is
similar to user-oriented admission control.</li>
<li>Adaptive admission control, reject more incoming requests restrictedly and
relax the admission control for mild overload situation. DAGOR combines the
above two schemes with respect to the individual load status. Based on the
result of load detection, the server increases/decreases the expected amount of
incoming requests. Then the sever can set a proper business and user priority.</li>
<li>Collaborative admission control, the downstream server sends its admission level to the upstream server such that some requests can be rejected by the upstream server early.</li>
</ul>

<p>DAROR has been deployed in Wechat for more than five year, demonstrating its effectiveness and robustness. A practical design indeed.</p>
]]></content>
    </item>
    
    <item>
      <title>Clay codes: Moulding MDS Codes to Yield an MSR Code, FAST &#39;18</title>
      <link>https://millyz.github.io/blog/posts/claycodes-fast18/</link>
      <pubDate>Mon, 29 Oct 2018 19:00:00 +0800</pubDate>
      
      <guid>https://millyz.github.io/blog/posts/claycodes-fast18/</guid>
      <description>The title attracts me at the first sight. How do the authors switch a MDS code to a MSR code though they belong to different classes of erasure codes from my understanding? After reading the abstract, a big question mark arises over my head as the properties of this code seems rather promising. This new code, termed as Clay codes (short for Coupled-Layer), achieves the following properties:
 Low storage overhead; Optimal in repair bandwidth, sub-packetization level and disk I/O; Uniform repair performance of data and parity nodes; Support for both single and multiple-node repairs, while permitting faster and more efficient repair.</description>
      <content type="html"><![CDATA[

<p>The title attracts me at the first sight. How do the authors switch a MDS code to
a MSR code though they belong to different classes of erasure codes from my
understanding? After reading the abstract, a big question mark arises over my
head as the properties of this code seems rather promising. This new code,
termed as <em>Clay codes</em> (short for Coupled-Layer), achieves the following
properties:</p>

<ol>
<li>Low storage overhead;</li>
<li>Optimal in repair bandwidth, sub-packetization level and disk I/O;</li>
<li>Uniform repair performance of data and parity nodes;</li>
<li>Support for both single and multiple-node repairs, while permitting faster
and more efficient repair.</li>
</ol>

<p>We can look at how Clay codes offer these advantages one by one later.  Before
going into the details of Clay codes, we first review the motivation and
challenges of this work.  In my opinion, they really try to solve
a challenging and practical problem. Now more and more distributed storage
systems employ erasure coding to protect data against failures. And one class of
widely-used erasure codes is <em>Maximum Distance Separable (MDS) codes</em>, e.g.,
Reed-Solomon codes. However, MDS codes incur high repair bandwidth while they
offer minimum storage overhead. Therefore, another class of codes named
<em>Minimum Storage Regenerating (MSR) codes</em> is proposed to minimize the repair
bandwidth cost while keeping low storage overhead and tolerating faults as MDS
codes. But the authors think the current MSR codes are not practical enough to
adopt in real-world storage systems. They consider the following points:</p>

<ul>
<li>Complex computation, e.g., nccloud;</li>
<li>Non-uniform repair for different types of node failures, e.g., HashTag;</li>
<li>Tolerate limited number of failures, e.g., Butterfly;</li>
<li>Uncommon construction of erasure codes, e.g., PM-RMT, Butterfly.</li>
</ul>

<p>Well, Clay codes do beat the existing MSR codes from the following
perspectives. Actually this paper can be considered as an extension of their
previous paper. The key idea of Clay codes is &ldquo;Clay codes are constructed by
placing any MDS code in multiple layers and performing pair-wise coupling
across layers.&rdquo; No magic in computer science but math exists. They add
additional computation to encoding/decoding such that minimum data can complete
the recovery as MSR codes. During encoding, Clay codes convert to uncoupled
code via pairwise reverse transform (PRT), perform MDS encoding, then turn back
to coupled codes via pairwise forward transform (PFT). For single-node
recovery, Clay codes first perform PRT to obtain the uncoupled code, MDS
decoding, and then compute the coupled element. Briefly speaking, the less
repair bandwidth cost derives from the coupling (or spreading data across
layers), i.e., any two sub-chunks out of {U, U∗, C, C∗} can be computed from
remaining two (Q: why not one-to-one?).  Detailed explanation can be found in
the slides.</p>

<p>They implement Clay codes on Ceph, which is the first vector codes running on
Ceph. In the evaluation, they compare Clay codes with RS codes, which I think
can be better if considering other MSR codes. Hope I can implement it by myself
someday and continue to compare it with other erasure codes.</p>

<h2 id="references">References:</h2>

<ul>
<li><a href="https://www.usenix.org/system/files/conference/fast18/fast18-vajha.pdf" target="_blank">Paper</a></li>
<li><a href="https://www.usenix.org/sites/default/files/conference/protected-files/fast18_slides_vajha.pdf" target="_blank">Authors&rsquo;
slides</a></li>
</ul>
]]></content>
    </item>
    
  </channel>
</rss>
